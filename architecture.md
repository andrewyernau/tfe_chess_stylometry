# Architecture Document - Chess Stylometry TFE

**Generated by**: architect-agent  
**Date**: 2024-10-08  
**Version**: 1.0  
**Model**: Opus

---

## Executive Summary

This document describes the architecture of the Chess Stylometry TFE project, a telecommunications engineering final project focused on AI-driven chess pattern analysis. The system analyzes chess games to identify players based on their characteristic play patterns (stylometry) through visual encodings and machine learning models.

## Table of Contents

1. [System Overview](#system-overview)
2. [Architecture Diagrams](#architecture-diagrams)
3. [Component Descriptions](#component-descriptions)
4. [Data Flow](#data-flow)
5. [Technology Stack](#technology-stack)
6. [Agent System](#agent-system)
7. [Development Workflow](#development-workflow)
8. [Future Extensions](#future-extensions)

---

## System Overview

The Chess Stylometry project implements a pipeline for:

1. **Data Ingestion**: Processing PGN (Portable Game Notation) chess game files
2. **Feature Extraction**: Converting game moves into visual representations (heatmaps, trajectories, board states)
3. **Model Training**: Training CNN/Transformer models to identify players from anonymized games
4. **Evaluation**: Assessing identification accuracy and analyzing patterns

The architecture follows a modular design with clear separation between data processing, visualization, modeling, and agent automation.

---

## Architecture Diagrams

### High-Level System Architecture

```mermaid
graph TB
    subgraph "Data Sources"
        A[Lichess/Chess.com<br/>PGN Files] --> B[labs/dataset/]
    end
    
    subgraph "Processing Pipeline"
        B --> C[PGN Parser<br/>python-chess]
        C --> D[Visual Encoder<br/>Heatmaps/Trajectories]
        D --> E[labs/dataset/generated/<br/>Images + Labels]
    end
    
    subgraph "Machine Learning"
        E --> F[Data Splits<br/>Train/Val/Test]
        F --> G[Model Training<br/>CNN/Transformer]
        G --> H[labs/models/<br/>Checkpoints]
        H --> I[Evaluation<br/>Metrics & Analysis]
    end
    
    subgraph "Visualization & Output"
        I --> J[labs/output/<br/>Reports & Visualizations]
    end
    
    subgraph "Research & Documentation"
        K[lib/<br/>Papers & References] -.-> C
        K -.-> D
        K -.-> G
    end
    
    style A fill:#e1f5fe
    style E fill:#f3e5f5
    style H fill:#e8f5e9
    style J fill:#fff3e0
    style K fill:#fce4ec
```

### Repository Structure

```mermaid
graph TD
    ROOT[jupyter/] --> CONTEXT[context/<br/>Agent Context & Metadata]
    ROOT --> LIB[lib/<br/>Papers & References]
    ROOT --> LABS[labs/<br/>Main Code]
    ROOT --> AGENTS[Agent System]
    
    LABS --> DATASET[dataset/<br/>PGN Files]
    LABS --> NOTEBOOKS[notebooks/<br/>Jupyter Analysis]
    LABS --> SRC[src/<br/>Scripts]
    LABS --> MODELS[models/<br/>Checkpoints]
    LABS --> UTILS[utils/<br/>Utilities]
    LABS --> OUTPUT[output/<br/>Results]
    
    DATASET --> GENERATED[generated/<br/>Images]
    DATASET --> SPLITS[splits/<br/>Train/Val/Test]
    
    AGENTS --> CLI[agent_cli.py]
    AGENTS --> WRAPPER[agents.py]
    AGENTS --> MAKE[Makefile]
    AGENTS --> ARCHMD[ARCHITECT.md]
    
    CONTEXT --> CTX[repo_context.json]
    
    style ROOT fill:#1976d2,color:#fff
    style LABS fill:#388e3c,color:#fff
    style AGENTS fill:#f57c00,color:#fff
    style CONTEXT fill:#7b1fa2,color:#fff
    style LIB fill:#c2185b,color:#fff
```

### Data Flow Architecture

```mermaid
flowchart LR
    subgraph Input
        A[PGN Files] --> B[Parser]
    end
    
    subgraph Encoding
        B --> C{Encoding Type}
        C -->|Heatmap| D[Heatmap Generator]
        C -->|Trajectory| E[Trajectory Generator]
        C -->|Board State| F[Board State Generator]
        C -->|Vector Field| G[Vector Field Generator]
    end
    
    subgraph Storage
        D --> H[(Image Dataset)]
        E --> H
        F --> H
        G --> H
        H --> I[Dataset Splitter]
        I --> J[Train Set]
        I --> K[Val Set]
        I --> L[Test Set]
    end
    
    subgraph Training
        J --> M[Model Training]
        K --> M
        M --> N[Model Checkpoints]
    end
    
    subgraph Evaluation
        L --> O[Inference]
        N --> O
        O --> P[Metrics & Reports]
    end
    
    style A fill:#64b5f6
    style H fill:#ba68c8
    style N fill:#81c784
    style P fill:#ffb74d
```

### Agent System Architecture

```mermaid
graph TB
    subgraph "User Interface"
        A[make init] --> B[AgentCLI]
        C[make list] --> B
        D[make agent NAME=X] --> B
    end
    
    subgraph "Agent CLI Core"
        B --> E[agents.py<br/>Command Wrapper]
        E --> F[agent_cli.py<br/>Core Logic]
    end
    
    subgraph "Agent Discovery"
        F --> G[Scan *.md files]
        G --> H[Parse Frontmatter]
        H --> I{Valid Agent?}
        I -->|Yes| J[Register Agent]
        I -->|No| K[Skip/Warning]
    end
    
    subgraph "Context Generation"
        F --> L[Scan Repository]
        L --> M[Build Structure Tree]
        M --> N[Detect Files]
        N --> O[context/repo_context.json]
    end
    
    subgraph "Agent Definitions"
        P[ARCHITECT.md] -.-> G
        Q[Future: DATA-ANALYST.md] -.-> G
        R[Future: MODEL-TRAINER.md] -.-> G
    end
    
    subgraph "Agent Execution"
        J --> S[Load Agent Config]
        O --> S
        S --> T[Execute Agent Task]
    end
    
    style B fill:#2196f3,color:#fff
    style F fill:#4caf50,color:#fff
    style O fill:#ff9800,color:#fff
    style T fill:#9c27b0,color:#fff
```

### Component Interaction

```mermaid
sequenceDiagram
    participant U as User
    participant M as Makefile
    participant W as agents.py
    participant C as agent_cli.py
    participant F as File System
    participant A as Agent
    
    U->>M: make init
    M->>W: /init command
    W->>C: cmd_init()
    C->>F: Scan repository
    F-->>C: Files & structure
    C->>F: Save repo_context.json
    C-->>U: ✓ Context initialized
    
    U->>M: make agent NAME=architect
    M->>W: /agent architect
    W->>C: cmd_agent('architect')
    C->>F: Load repo_context.json
    C->>F: Load ARCHITECT.md
    F-->>C: Agent config
    C->>A: Initialize with context
    A->>A: Execute tasks
    A-->>U: Results (architecture.md)
```

---

## Component Descriptions

### Core Modules

#### 1. **Data Layer** (`labs/dataset/`)

**Purpose**: Storage and organization of chess game data

**Components**:
- `chessgame0001.pgn`: Raw PGN game files
- `generated/`: Processed visual representations (images)
- `splits/`: Train/validation/test data partitions

**Technologies**: File system, PGN format

#### 2. **Processing Layer** (`labs/src/`, `labs/notebooks/`)

**Purpose**: Data parsing, feature extraction, and visualization

**Components**:
- PGN parsers (python-chess)
- Visual encoding generators
- Jupyter notebooks for experimentation (`chess-0000-preview.ipynb`)

**Technologies**: 
- Python 3.12
- python-chess
- numpy, pandas
- matplotlib, cairosvg

#### 3. **Model Layer** (`labs/models/`)

**Purpose**: Machine learning model definitions and checkpoints

**Components**:
- CNN architectures for image classification
- Transformer models for sequence analysis
- Trained model checkpoints

**Technologies**: 
- PyTorch / TensorFlow (to be determined)
- Scikit-learn for utilities

#### 4. **Output Layer** (`labs/output/`)

**Purpose**: Generated visualizations, reports, and evaluation results

**Components**:
- Training plots and metrics
- Confusion matrices
- Stylometric fingerprint visualizations

#### 5. **Agent System** (`agent_cli.py`, `agents.py`, `Makefile`)

**Purpose**: Automated task execution and repository management

**Components**:
- **agent_cli.py** (367 lines): Core CLI with agent discovery, parsing, and context generation
- **agents.py** (58 lines): Simplified command wrapper
- **Makefile**: Convenient command shortcuts
- **context/repo_context.json**: Generated repository metadata

**Key Features**:
- Auto-discovery of agents from `.md` files
- Frontmatter YAML parsing
- Repository context generation
- Validation and error handling

**Current Agents**:
- `architect`: System architecture analysis and documentation

#### 6. **Research Library** (`lib/`)

**Purpose**: Reference materials and research papers

**Resources**:
- `chess_rating_estimation.pdf`
- `detection_stylometry.pdf`

---

## Data Flow

### 1. Ingestion Phase

```
PGN Files → Parser → Structured Game Data
```

**Input**: Raw PGN files from Lichess/Chess.com  
**Processing**: Parse moves, metadata, player info  
**Output**: Structured game objects

### 2. Encoding Phase

```
Structured Data → Visual Encoders → Images
```

**Encodings**:
- **Heatmaps**: Piece movement frequency
- **Trajectories**: Move sequence paths
- **Board States**: Position snapshots
- **Vector Fields**: Directional movement patterns

### 3. Training Phase

```
Images + Labels → Dataset Splits → Model Training → Checkpoints
```

**Process**:
1. Split data (70/15/15 train/val/test)
2. Apply data augmentation
3. Train CNN/Transformer models
4. Save checkpoints and metrics

### 4. Evaluation Phase

```
Test Set + Model → Inference → Metrics + Visualizations
```

**Outputs**:
- Accuracy, precision, recall, F1
- Confusion matrices
- Error analysis
- Stylometric comparisons

---

## Technology Stack

### Programming Languages
- **Python 3.12**: Primary language

### Data Processing
- **python-chess**: PGN parsing and chess logic
- **pandas**: Tabular data manipulation
- **numpy**: Numerical operations

### Visualization
- **matplotlib**: Plotting and charting
- **seaborn**: Statistical visualizations
- **cairosvg**: SVG to PNG conversion

### Machine Learning
- **PyTorch / TensorFlow**: Deep learning frameworks (TBD)
- **scikit-learn**: ML utilities and metrics

### Development Tools
- **Jupyter**: Interactive notebooks
- **Git**: Version control
- **Make**: Build automation

### Agent System
- **Python stdlib**: argparse, pathlib, json, re, dataclasses
- **Type annotations**: PEP 484 compliance
- **Frontmatter parsing**: Custom YAML parser

---

## Agent System

### Architecture Pattern

The agent system follows a **Plugin Architecture** pattern:

1. **Discovery**: Agents are discovered by scanning `.md` files in the repository root
2. **Registration**: Valid agents with proper frontmatter are registered
3. **Execution**: Agents are loaded with full context and executed on demand

### Agent Definition Format

```markdown
---
name: agent-name
description: Agent description
model: opus|sonnet|haiku
tools: tool1, tool2, tool3
---

Agent documentation and instructions here.
```

### Agent Lifecycle

```mermaid
stateDiagram-v2
    [*] --> Discovery: make init
    Discovery --> Parsing: Found .md file
    Parsing --> Validation: Extract frontmatter
    Validation --> Registration: Valid
    Validation --> Skip: Invalid
    Registration --> Context: Add to repo_context.json
    Skip --> Discovery
    Context --> Ready: Agent available
    Ready --> Execution: make agent NAME=X
    Execution --> Task: Load config + context
    Task --> Result: Generate output
    Result --> [*]
```

### Current Agents

#### architect-agent
- **Model**: Opus (high-capacity)
- **Tools**: code-search, repo-analyzer, Mermaid
- **Purpose**: Analyze repository architecture and generate documentation
- **Output**: This architecture.md document

### Future Agents (Planned)

#### data-analyst-agent
- **Model**: Sonnet
- **Tools**: pandas, numpy, matplotlib
- **Purpose**: Analyze PGN datasets and generate statistical reports

#### model-trainer-agent
- **Model**: Sonnet
- **Tools**: PyTorch, scikit-learn
- **Purpose**: Train and evaluate chess stylometry models

#### visualizer-agent
- **Model**: Haiku
- **Tools**: matplotlib, seaborn
- **Purpose**: Generate visual encodings from PGN data

---

## Development Workflow

### 1. Research Phase
- Review papers in `lib/`
- Explore encoding strategies
- Design experiments

### 2. Data Preparation
- Collect PGN files → `labs/dataset/`
- Parse and validate games
- Generate visual encodings → `labs/dataset/generated/`

### 3. Experimentation
- Prototype in Jupyter notebooks → `labs/notebooks/`
- Iterate on encodings and features
- Visualize results

### 4. Production Scripts
- Convert notebooks to Python scripts → `labs/src/`
- Implement utilities → `labs/utils/`
- Automate pipeline

### 5. Model Development
- Define model architectures
- Train on prepared datasets
- Save checkpoints → `labs/models/`

### 6. Evaluation
- Run inference on test set
- Generate metrics and reports
- Save outputs → `labs/output/`

### 7. Agent Automation
- Use `make init` to update context
- Use `make agent NAME=X` to automate tasks
- Extend with new agents as needed

---

## Future Extensions

### Short Term
1. **Data Pipeline Automation**
   - Create data-analyst agent for PGN analysis
   - Automate encoding generation

2. **Model Training Automation**
   - Implement model-trainer agent
   - Hyperparameter tuning workflows

3. **Visualization Enhancement**
   - Create visualizer agent
   - Interactive dashboards

### Medium Term
1. **Advanced Encodings**
   - Stacked trajectories
   - Vector field representations
   - Temporal heatmaps

2. **Model Diversity**
   - Transformer-based models
   - Ensemble methods
   - Transfer learning from chess engines

3. **Agent Ecosystem**
   - More specialized agents
   - Agent collaboration patterns
   - Automated testing agents

### Long Term
1. **Web Interface**
   - Flask/FastAPI backend
   - React frontend
   - Real-time analysis

2. **Distributed Training**
   - Multi-GPU support
   - Cloud deployment
   - Scalable pipelines

3. **Production Deployment**
   - API endpoints
   - Model serving
   - Continuous learning

---

## Appendix

### File Statistics

| Category | Count | Details |
|----------|-------|---------|
| Python Files | 2 | agent_cli.py (367 lines), agents.py (58 lines) |
| Notebooks | 1 | chess-0000-preview.ipynb |
| Agents | 1 | architect |
| PGN Files | 1 | chessgame0001.pgn |
| Papers | 2 | chess_rating_estimation.pdf, detection_stylometry.pdf |
| Key Directories | 10 | Full project structure |

### Repository Metrics

- **Total Lines of Agent Code**: 425 lines
- **Documentation Files**: 7 (README, AGENTS, ARCHITECT, AGENT_CLI, QUICKSTART, EJEMPLO_USO, this document)
- **Agent System Version**: 1.0
- **Python Version**: 3.12
- **Repository Type**: Research & Development

### Context File Structure

```json
{
  "repo_root": "/path/to/jupyter",
  "structure": { /* directory tree */ },
  "agents": { /* registered agents */ },
  "metadata": {
    "python_files": [],
    "notebooks": [],
    "key_directories": []
  }
}
```

---

## Conclusion

The Chess Stylometry TFE project implements a well-structured, modular architecture for analyzing chess playing patterns through visual encodings and machine learning. The addition of an agent system enables automated task execution and improves development workflow efficiency.

**Key Strengths**:
- ✅ Clear separation of concerns
- ✅ Modular, extensible design
- ✅ Automated agent system
- ✅ Comprehensive documentation
- ✅ Research-backed approach

**Next Steps**:
1. Implement data processing pipeline
2. Create additional agents (data-analyst, model-trainer)
3. Train initial CNN models
4. Evaluate and iterate

---

**Document Generated by**: architect-agent  
**Tools Used**: code-search, repo-analyzer, Mermaid  
**Model**: Opus  
**Date**: 2025-10-08
